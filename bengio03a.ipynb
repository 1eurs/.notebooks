{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e8a91c-79d5-4cf5-a0f5-59858b1c15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42858e18-73c5-403b-baa7-02538b44be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6b786f-d711-477e-bd2d-f462b4bb8a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrs = sorted(list(set([ch for word in words for ch in word])))\n",
    "chrs = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chrs)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c821483d-a273-424b-a490-1401bef2e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    block_size = 3\n",
    "    X ,Y = [], []\n",
    "    \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    \n",
    "    Y = torch.tensor(Y)\n",
    "    X = torch.tensor(X)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b305ac-e38e-40bd-b541-eaf1952572d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1]) \n",
    "Xdev, Ydev = build_dataset(words[n1:n2]) \n",
    "Xte, Yte = build_dataset(words[n2:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1394f6f-6747-496f-a9fb-9802f6e0ae42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11897"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn(27,10)\n",
    "w1 = torch.randn(30,200)\n",
    "b1 = torch.randn(200)\n",
    "w2 = torch.randn(200,27)\n",
    "b2 = torch.randn(27)\n",
    "parameters = [C, w1, b1, w2, b2]  \n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "total_params = sum([p.nelement() for p in parameters])\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c62d181-f250-407c-98d0-f1984948f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000); lrs = 10**lre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e2288e-8801-46f2-9c7b-ddda68ce4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "lri = []\n",
    "lossi = []\n",
    "stepi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c866c9a1-6d2a-4bd8-a287-c77c518fec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, Loss: 9.497306823730469\n",
      "Iteration 200, Loss: 4.848949432373047\n",
      "Iteration 300, Loss: 5.90245246887207\n",
      "Iteration 400, Loss: 6.966673851013184\n",
      "Iteration 500, Loss: 3.924912929534912\n",
      "Iteration 600, Loss: 5.5319905281066895\n",
      "Iteration 700, Loss: 3.967810869216919\n",
      "Iteration 800, Loss: 5.106926918029785\n",
      "Iteration 900, Loss: 4.831754684448242\n",
      "Iteration 1000, Loss: 4.276760101318359\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "\n",
    "    # minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0],(32,))\n",
    "    \n",
    "    # Forward pass\n",
    "    emb = C[Xtr][ix] # 32,3,2\n",
    "    h = torch.tanh((emb.view(-1, 30) @ w1) + b1)  #(32,6 @ 6,100) = (32,100)\n",
    "    logits = h @ w2 + b2\n",
    "    loss = F.cross_entropy(logits, Ytr[ix])\n",
    "    \n",
    "    if (i + 1) % 100 == 0: \n",
    "        print(f\"Iteration {i + 1}, Loss: {loss.item()}\")\n",
    "    \n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward() \n",
    "    \n",
    "    # Update\n",
    "    # lr = lrs[i]\n",
    "    # lr = 0.1 if i < 10000 else 0.01\n",
    "    lr = 0.1 * (1 + torch.cos(torch.tensor(i / 5000 * 3.14159))) / 2\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.data +=  -lr * p.grad\n",
    "\n",
    "    # track stats|\n",
    "    # lri.append(lre[i])\n",
    "    stepi.append(i)\n",
    "    lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12bf157-b3e2-4da5-8909-968213d68fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stepi,lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4773005-5605-4735-8781-93348fbe6dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[Xtr] # 32,3,2\n",
    "h = torch.tanh((emb.view(-1, 30) @ w1) + b1)  #(32,6 @ 6,100) = (32,100)\n",
    "logits = h @ w2 + b2\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b718deb0-9a60-4d0a-b6c7-d4b26b97a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[Xdev] # 32,3,2\n",
    "h = torch.tanh((emb.view(-1, 30) @ w1) + b1)  #(32,6 @ 6,100) = (32,100)\n",
    "logits = h @ w2 + b2\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a25f37-230d-484d-b3f8-b59f85c4541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(C[:,0].data , C[:,1].data, s= 200)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha = \"center\" , va= \"center\", color = \"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0295754-b9c2-434a-a498-a29f95aa8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, stoi, itos, block_size=3, max_len=10, seed_context=None):\n",
    "    context = [0] * block_size if seed_context is None else [stoi[c] for c in seed_context][-block_size:]\n",
    "    generated = []\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        x = torch.tensor([context], dtype=torch.long)\n",
    "        emb = model[0][x]  # C[X]: embedding lookup\n",
    "        h = torch.tanh(emb.view(-1, 30) @ model[1] + model[2])  # w1, b1\n",
    "        logits = h @ model[3] + model[4]  # w2, b2\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        ix = torch.multinomial(probs, num_samples=1).item()\n",
    "        generated.append(itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "        if ix == 0:  \n",
    "            break\n",
    "    \n",
    "    return ''.join(generated).replace('.', '')\n",
    "\n",
    "for _ in range(10):\n",
    "    generated_text = sample(parameters, stoi, itos, block_size=3, max_len=10)\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7edbc55-86a6-4a3a-a2c6-ae5fd785221b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
